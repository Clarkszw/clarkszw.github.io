{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d65e87d",
   "metadata": {},
   "source": [
    "\n",
    "# Exploring Hackers News Posts\n",
    "\n",
    "In this project, we'll compare two different types of posts from [Hacker News](https://news.ycombinator.com/), a popular site where technology related stories (or 'posts') are voted and commented upon. The two types of posts we'll explore begin with either `Ask HN` or `Show HN`.\n",
    "\n",
    "Users submit `Ask HN` posts to ask the Hacker News community a specific question, such as \"What is the best online course you've ever taken?\" Likewise, users submit `Show HN` posts to show the Hacker News community a project, product, or just generally something interesting.\n",
    "\n",
    "We'll specifically compare these two types of posts to determine the following:\n",
    "\n",
    "* Do `Ask HN` or `Show HN` receive more comments on average?\n",
    "* Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "It should be noted that the data set we're working with was reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions.\n",
    "\n",
    "## Read data\n",
    "\n",
    "First, we'll read in the data and have a first look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc76c8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12579008',\n",
       "  'You have two days to comment if you want stem cells to be classified as your own',\n",
       "  'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018',\n",
       "  '1',\n",
       "  '0',\n",
       "  'altstar',\n",
       "  '9/26/2016 3:26'],\n",
       " ['12579005',\n",
       "  'SQLAR  the SQLite Archiver',\n",
       "  'https://www.sqlite.org/sqlar/doc/trunk/README.md',\n",
       "  '1',\n",
       "  '0',\n",
       "  'blacksqr',\n",
       "  '9/26/2016 3:24'],\n",
       " ['12578997',\n",
       "  'What if we just printed a flatscreen television on the side of our boxes?',\n",
       "  'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43',\n",
       "  '1',\n",
       "  '0',\n",
       "  'pavel_lishin',\n",
       "  '9/26/2016 3:19'],\n",
       " ['12578989',\n",
       "  'algorithmic music',\n",
       "  'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext',\n",
       "  '1',\n",
       "  '0',\n",
       "  'poindontcare',\n",
       "  '9/26/2016 3:16']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data.\n",
    "from csv import reader\n",
    "\n",
    "open_file = open('hacker-news-posts.csv', encoding='utf-8')\n",
    "read_file = reader(open_file)\n",
    "hn = list(read_file)\n",
    "hn[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2649730",
   "metadata": {},
   "source": [
    "Notice that the first list in the inner lists contains the column headers, and the lists after contain the data for one row. In order to analyze our data, we need to first remove the row containing the column hearders\n",
    "\n",
    "## Removing Headers from a List of Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad45434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']]\n"
     ]
    }
   ],
   "source": [
    "# Remove the headers.\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers)\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1175ab1a",
   "metadata": {},
   "source": [
    "We can see above that the data set contains the title of the posts, the number of comments for each post, and the date the post was created. Let's start by exploring the number of comments for each type of post.\n",
    "\n",
    "## Extracting Ask HN and Show HN Posts\n",
    "\n",
    "First, we'll identify posts that begin with either Ask HN or Show HN and separate the data for those two types of posts into different lists. Separating the data makes it easier to analyze in the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2382bad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "10158\n",
      "273822\n"
     ]
    }
   ],
   "source": [
    "# Identify posts that begin with either `Ask HN` or `Show HN` and separate the data into different lists.\n",
    "ask_posts = []\n",
    "show_posts =[]\n",
    "other_posts = []\n",
    "\n",
    "for post in hn:\n",
    "    title = post[1]\n",
    "    if title.lower().startswith(\"ask hn\"):\n",
    "        ask_posts.append(post)\n",
    "    elif title.lower().startswith(\"show hn\"):\n",
    "        show_posts.append(post)\n",
    "    else:\n",
    "        other_posts.append(post)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f7f6f",
   "metadata": {},
   "source": [
    "## Calculating the Average Number of Comments for Ask HN and Show HN Posts\n",
    "\n",
    "Now that we separated ask posts and show posts into different lists, we'll calculate the average number of comments each type of post receives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a39a2391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.393478498741656\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average number of comments `Ask HN` posts receive.\n",
    "total_ask_comments = 0\n",
    "\n",
    "for post in ask_posts:\n",
    "    total_ask_comments += int(post[4])\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d057349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "\n",
    "for post in show_posts:\n",
    "    total_show_comments += int(post[4])\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebf3281",
   "metadata": {},
   "source": [
    "On average, ask posts in our sample receive approximately 10 comments, whereas show posts receive approximately 5. Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts.\n",
    "\n",
    "## Finding the Amount of Ask Posts and Comments by Hour Created\n",
    "\n",
    "Next, we'll determine if we can maximize the amount of comments an ask post receives by creating it at a certain time. First, we'll find the amount of ask posts created during each hour of day, along with the number of comments those posts received. Then, we'll calculate the average amount of comments ask posts created at each hour of the day receive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0716018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 2996,\n",
       " 1: 2089,\n",
       " 22: 3372,\n",
       " 21: 4500,\n",
       " 19: 3954,\n",
       " 17: 5547,\n",
       " 15: 18525,\n",
       " 14: 4972,\n",
       " 13: 7245,\n",
       " 11: 2797,\n",
       " 10: 3013,\n",
       " 9: 1477,\n",
       " 7: 1585,\n",
       " 3: 2154,\n",
       " 23: 2297,\n",
       " 20: 4462,\n",
       " 16: 4466,\n",
       " 8: 2362,\n",
       " 0: 2277,\n",
       " 18: 4877,\n",
       " 12: 4234,\n",
       " 4: 2360,\n",
       " 6: 1587,\n",
       " 5: 1838}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the amount of ask posts created during each hour of day and the number of comments received.\n",
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for post in ask_posts:\n",
    "    result_list.append(\n",
    "        [post[6], int(post[4])]\n",
    "    )\n",
    "\n",
    "comments_by_hour = {}\n",
    "counts_by_hour = {}\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    number_comment = row[1]\n",
    "    time = dt.datetime.strptime(date, date_format).hour\n",
    "    if time in counts_by_hour:\n",
    "        comments_by_hour[time] += number_comment\n",
    "        counts_by_hour[time] += 1\n",
    "    else:\n",
    "        comments_by_hour[time] = number_comment\n",
    "        counts_by_hour[time] = 1\n",
    "\n",
    "comments_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731601ba",
   "metadata": {},
   "source": [
    "## Calculating the Average Number of Comments for Ask HN Posts by Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e15d200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 11.137546468401487,\n",
       " 1: 7.407801418439717,\n",
       " 22: 8.804177545691905,\n",
       " 21: 8.687258687258687,\n",
       " 19: 7.163043478260869,\n",
       " 17: 9.449744463373083,\n",
       " 15: 28.676470588235293,\n",
       " 14: 9.692007797270955,\n",
       " 13: 16.31756756756757,\n",
       " 11: 8.96474358974359,\n",
       " 10: 10.684397163120567,\n",
       " 9: 6.653153153153153,\n",
       " 7: 7.013274336283186,\n",
       " 3: 7.948339483394834,\n",
       " 23: 6.696793002915452,\n",
       " 20: 8.749019607843136,\n",
       " 16: 7.713298791018998,\n",
       " 8: 9.190661478599221,\n",
       " 0: 7.5647840531561465,\n",
       " 18: 7.94299674267101,\n",
       " 12: 12.380116959064328,\n",
       " 4: 9.7119341563786,\n",
       " 6: 6.782051282051282,\n",
       " 5: 8.794258373205741}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the average amount of comments `Ask HN` posts created at each hour of the day receive.\n",
    "avg_by_hour = {}\n",
    "\n",
    "for hr in comments_by_hour:\n",
    "    avg_by_hour[hr] = comments_by_hour[hr] / counts_by_hour[hr]\n",
    "\n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be5003",
   "metadata": {},
   "source": [
    "## Sorting and Printing Values from a List of Lists\n",
    "\n",
    "### Find the max value in a Dictionary.\n",
    "\n",
    "First approach: inverse the dictionary items and assign to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d983a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28.676470588235293, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse = [(avg, hour) for hour , avg in avg_by_hour.items()]\n",
    "max(inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5584a514",
   "metadata": {},
   "source": [
    "Second approach: use ` dict.get()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d27b375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 28.676470588235293\n"
     ]
    }
   ],
   "source": [
    "key = max(avg_by_hour, key=avg_by_hour.get)\n",
    "value = max(avg_by_hour.values())\n",
    "print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31235f05",
   "metadata": {},
   "source": [
    "Third approach: use `operator.itemgetter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a4d55ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 28.676470588235293)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "max(avg_by_hour.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f224f",
   "metadata": {},
   "source": [
    "### Convert the Dictionary to list and then sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "153a13bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[28.676470588235293, 15],\n",
       " [16.31756756756757, 13],\n",
       " [12.380116959064328, 12],\n",
       " [11.137546468401487, 2],\n",
       " [10.684397163120567, 10],\n",
       " [9.7119341563786, 4],\n",
       " [9.692007797270955, 14],\n",
       " [9.449744463373083, 17],\n",
       " [9.190661478599221, 8],\n",
       " [8.96474358974359, 11],\n",
       " [8.804177545691905, 22],\n",
       " [8.794258373205741, 5],\n",
       " [8.749019607843136, 20],\n",
       " [8.687258687258687, 21],\n",
       " [7.948339483394834, 3],\n",
       " [7.94299674267101, 18],\n",
       " [7.713298791018998, 16],\n",
       " [7.5647840531561465, 0],\n",
       " [7.407801418439717, 1],\n",
       " [7.163043478260869, 19],\n",
       " [7.013274336283186, 7],\n",
       " [6.782051282051282, 6],\n",
       " [6.696793002915452, 23],\n",
       " [6.653153153153153, 9]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour_list = []\n",
    "\n",
    "for key, value in avg_by_hour.items():\n",
    "    avg_by_hour_list.append([value, key])\n",
    "\n",
    "sorted_list = sorted(avg_by_hour_list, reverse=True)\n",
    "\n",
    "sorted_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4a9dbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for 'Ask HN' Comments\n",
      "15:00: 28.68 average comments per post\n",
      "13:00: 16.32 average comments per post\n",
      "12:00: 12.38 average comments per post\n",
      "02:00: 11.14 average comments per post\n",
      "10:00: 10.68 average comments per post\n"
     ]
    }
   ],
   "source": [
    "# Sort the values and print the the 5 hours with the highest average comments.\n",
    "\n",
    "print(\"Top 5 Hours for 'Ask HN' Comments\")\n",
    "for avg, hr in sorted_list[:5]:\n",
    "    hour = dt.datetime.strptime(str(hr), \"%H\").strftime(\"%H:%M\")\n",
    "    print(\n",
    "        \"{}: {:.2f} average comments per post\".format(hour ,avg)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1761ba2",
   "metadata": {},
   "source": [
    "The hour that receives the most comments per post on average is 15:00, with an average of 28.68 comments per post. There's about a 75% increase in the number of comments between the hours with the highest and second highest average number of comments.\n",
    "\n",
    "According to the data set [documentation](https://www.kaggle.com/hacker-news/hacker-news-posts/home), the timezone used is Eastern Time in the US. So, we could also write 15:00 as 3:00 pm est.\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "In this project, we analyzed ask posts and show posts to determine which type of post and time receive the most comments on average. Based on our analysis, to maximize the amount of comments a post receives, we'd recommend the post be categorized as ask post and created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est).\n",
    "\n",
    "However, it should be noted that the data set we analyzed excluded posts without any comments. Given that, it's more accurate to say that of the posts that received comments, ask posts received more comments on average and ask posts created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est) received the most comments on average."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
